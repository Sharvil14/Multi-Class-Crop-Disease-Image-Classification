{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_c_WCc-ItYc",
        "outputId": "d1877f1d-017f-4273-d11b-b471d186f1c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /kaggle/input/20k-multi-class-crop-disease-images\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "path = kagglehub.dataset_download(\"jawadali1045/20k-multi-class-crop-disease-images\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ffc5988f",
        "outputId": "3abf99d4-a15f-4d88-d594-64b43589c07f"
      },
      "source": [
        "import kagglehub\n",
        "import os\n",
        "from PIL import Image\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Rescaling, RandomFlip, RandomRotation, RandomZoom\n",
        "\n",
        "# Load the dataset\n",
        "path = kagglehub.dataset_download(\"jawadali1045/20k-multi-class-crop-disease-images\")\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "dataset_path = path\n",
        "train_path = os.path.join(dataset_path, 'Train')\n",
        "validation_path = os.path.join(dataset_path, 'Validation')\n",
        "\n",
        "\n",
        "# Explore the dataset (optional, for verification)\n",
        "print(\"\\nContents of Train directory:\")\n",
        "train_classes = os.listdir(train_path)\n",
        "print(train_classes)\n",
        "\n",
        "print(\"\\nContents of Validation directory:\")\n",
        "validation_classes = os.listdir(validation_path)\n",
        "print(validation_classes)\n",
        "\n",
        "# Count images in each class within Train and Validation (optional, for verification)\n",
        "train_class_counts = {}\n",
        "print(\"\\nTrain Class distribution:\")\n",
        "for class_name in train_classes:\n",
        "    class_dir = os.path.join(train_path, class_name)\n",
        "    if os.path.isdir(class_dir):\n",
        "        image_files = [f for f in os.listdir(class_dir) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
        "        train_class_counts[class_name] = len(image_files)\n",
        "        print(f\"{class_name}: {len(image_files)} images\")\n",
        "\n",
        "validation_class_counts = {}\n",
        "print(\"\\nValidation Class distribution:\")\n",
        "for class_name in validation_classes:\n",
        "    class_dir = os.path.join(validation_path, class_name)\n",
        "    if os.path.isdir(class_dir):\n",
        "        image_files = [f for f in os.listdir(class_dir) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
        "        validation_class_counts[class_name] = len(image_files)\n",
        "        print(f\"{class_name}: {len(image_files)} images\")\n",
        "\n",
        "\n",
        "# Define image dimensions and batch size\n",
        "img_height = 128\n",
        "img_width = 128\n",
        "batch_size = 32\n",
        "\n",
        "# Get the class names by inspecting the directories\n",
        "class_names = sorted([name for name in os.listdir(train_path) if os.path.isdir(os.path.join(train_path, name))])\n",
        "print(\"Class names:\", class_names)\n",
        "num_classes = len(class_names)\n",
        "print(\"Number of classes:\", num_classes)\n",
        "\n",
        "# Function to safely parse image and label from file path\n",
        "def safe_parse_image(file_path_tensor, class_names_tensor):\n",
        "    file_path = file_path_tensor.numpy().decode('utf-8')\n",
        "    class_names = [name.decode('utf-8') for name in class_names_tensor.numpy()]\n",
        "\n",
        "    try:\n",
        "        # Extract label from the parent directory name\n",
        "        parts = file_path.split(os.sep)\n",
        "        class_name = parts[-2]\n",
        "        try:\n",
        "            label = class_names.index(class_name)\n",
        "        except ValueError:\n",
        "             print(f\"Warning: Class name '{class_name}' not found in class_names.\")\n",
        "             return tf.zeros(shape=(img_height, img_width, 3), dtype=tf.float32), tf.constant(-1, dtype=tf.int64)\n",
        "\n",
        "\n",
        "        # Read and decode image\n",
        "        img = tf.io.read_file(file_path)\n",
        "        img = tf.image.decode_image(img, channels=3, expand_animations=False)\n",
        "\n",
        "        # Check if the image is successfully decoded and has expected channels\n",
        "        if img.shape.rank == 3 and img.shape[-1] == 3:\n",
        "             img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "             img = tf.image.resize(img, [img_height, img_width])\n",
        "             return img, tf.constant(label, dtype=tf.int64)\n",
        "        else:\n",
        "             # Return placeholder for invalid images with correct shape\n",
        "             print(f\"Warning: Invalid image shape for {file_path}\")\n",
        "             return tf.zeros(shape=(img_height, img_width, 3), dtype=tf.float32), tf.constant(-1, dtype=tf.int64)\n",
        "\n",
        "    except Exception as e:\n",
        "        # Handle decoding errors by returning placeholder with correct shape\n",
        "        tf.print(f\"Error decoding image {file_path}: {e}\")\n",
        "        return tf.zeros(shape=(img_height, img_width, 3), dtype=tf.float32), tf.constant(-1, dtype=tf.int64)\n",
        "\n",
        "\n",
        "# Wrapper function to use safe_parse_image with tf.py_function\n",
        "@tf.function\n",
        "def tf_safe_parse_image(file_path):\n",
        "    # Pass class_names as a tensor to tf.py_function\n",
        "    img, label = tf.py_function(\n",
        "        func=safe_parse_image,\n",
        "        inp=[file_path, tf.constant(class_names, dtype=tf.string)],\n",
        "        Tout=[tf.float32, tf.int64]\n",
        "    )\n",
        "    # Explicitly set the shape of the output tensors\n",
        "    img.set_shape((img_height, img_width, 3))\n",
        "    label.set_shape(()) # Scalar label\n",
        "    return img, label\n",
        "\n",
        "# Function to filter out invalid entries (where label is -1)\n",
        "def filter_invalid_entries(image, label):\n",
        "    return tf.not_equal(label, -1)\n",
        "\n",
        "\n",
        "# Get list of all image file paths in the train directory\n",
        "train_list_ds = tf.data.Dataset.list_files(os.path.join(train_path, '*/*'))\n",
        "\n",
        "# Get list of all image file paths in the validation directory\n",
        "test_list_ds = tf.data.Dataset.list_files(os.path.join(validation_path, '*/*'))\n",
        "\n",
        "\n",
        "# Determine the size of the dataset by counting files manually\n",
        "valid_train_files = [os.path.join(root, file) for root, _, files in os.walk(train_path) for file in files if file.lower().endswith(('.jpg', '.png', '.jpeg', '.bmp', '.gif'))]\n",
        "dataset_size = len(valid_train_files)\n",
        "print(f\"Found {dataset_size} potential image files in the training directory.\")\n",
        "\n",
        "\n",
        "# Split the list of file paths into train and validation sets\n",
        "train_size = int(0.8 * dataset_size)\n",
        "val_size = dataset_size - train_size # The rest for validation\n",
        "\n",
        "# Shuffle and take for splitting\n",
        "train_list_ds = train_list_ds.shuffle(dataset_size, seed=42).take(train_size)\n",
        "val_list_ds = train_list_ds.skip(train_size).take(val_size) # Split from the shuffled train list\n",
        "\n",
        "\n",
        "# Create train and validation datasets by mapping the safe parsing function\n",
        "train_ds = train_list_ds.map(tf_safe_parse_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "val_ds = val_list_ds.map(tf_safe_parse_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "# Filter out any invalid entries resulting from decoding errors\n",
        "train_ds = train_ds.filter(filter_invalid_entries)\n",
        "val_ds = val_ds.filter(filter_invalid_entries)\n",
        "\n",
        "\n",
        "# Create test dataset from the validation folder and filter invalid entries\n",
        "test_ds = test_list_ds.map(tf_safe_parse_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "test_ds = test_ds.filter(filter_invalid_entries)\n",
        "\n",
        "\n",
        "# Batch the datasets\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_ds = train_ds.batch(batch_size).cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.batch(batch_size).cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "test_ds = test_ds.batch(batch_size).cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "print(\"\\nDatasets created and optimized using manual loading with error handling and explicit shape setting.\")\n",
        "\n",
        "# Add data augmentation layers\n",
        "data_augmentation = Sequential([\n",
        "    RandomFlip(\"horizontal_and_vertical\"),\n",
        "    RandomRotation(0.2),\n",
        "    RandomZoom(0.2),\n",
        "])\n",
        "\n",
        "# Define the CNN model architecture\n",
        "model = Sequential([\n",
        "    # Data augmentation layer\n",
        "    data_augmentation,\n",
        "    # Rescaling layer to normalize pixel values - provide input_shape here\n",
        "    Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
        "\n",
        "    # Convolutional and Pooling layers\n",
        "    Conv2D(16, kernel_size=(3, 3), activation='relu', padding='same'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    # Flatten the output for the dense layers\n",
        "    Flatten(),\n",
        "\n",
        "    # Dense layers for classification\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(num_classes, activation='softmax') # Output layer with softmax for multi-class classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "epochs = 15 # Define the number of training epochs\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=epochs\n",
        ")\n",
        "\n",
        "# Print model summary\n",
        "model.summary()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset files: /kaggle/input/20k-multi-class-crop-disease-images\n",
            "\n",
            "Contents of Train directory:\n",
            "['bacterial_blight in Cotton', 'RedRust sugarcane', 'Healthy Maize', 'Wheat___Yellow_Rust', 'Tungro', 'Wheat mite', 'Anthracnose on Cotton', 'Healthy Wheat', 'Cotton Aphid', 'Common_Rust', 'American Bollworm on Cotton', 'Yellow Rust Sugarcane', 'Flag Smut', 'Wheat scab', 'Army worm', 'cotton whitefly', 'Wheat leaf blight', 'Healthy cotton', 'Wilt', 'bollrot on Cotton', 'Rice Blast', 'Becterial Blight in Rice', 'cotton mealy bug', 'maize ear rot', 'Wheat Stem fly', 'Mosaic sugarcane', 'Sugarcane Healthy', 'red cotton bug', 'maize stem borer', 'Brownspot', 'bollworm on Cotton', 'pink bollworm in cotton', 'Leaf Curl', 'Wheat aphid', 'maize fall armyworm', 'Wheat Brown leaf Rust', 'Leaf smut', 'Wheat black rust', 'thirps on  cotton', 'RedRot sugarcane', 'Gray_Leaf_Spot', 'Wheat powdery mildew']\n",
            "\n",
            "Contents of Validation directory:\n",
            "['RedRust sugarcane', 'Healthy Maize', 'Wheat___Yellow_Rust', 'Tungro', 'Wheat mite', 'Anthracnose on Cotton', 'Healthy Wheat', 'Cotton Aphid', 'Common_Rust', 'American Bollworm on Cotton', 'Yellow Rust Sugarcane', 'Flag Smut', 'Wheat scab', 'Army worm', 'cotton whitefly', 'Bacterial Blight in cotton', 'Wheat leaf blight', 'Healthy cotton', 'Wilt', 'bollrot on Cotton', 'Rice Blast', 'Becterial Blight in Rice', 'cotton mealy bug', 'maize ear rot', 'Wheat Stem fly', 'Mosaic sugarcane', 'Sugarcane Healthy', 'red cotton bug', 'maize stem borer', 'Brownspot', 'bollworm on Cotton', 'pink bollworm in cotton', 'Leaf Curl', 'Wheat aphid', 'maize fall armyworm', 'Wheat Brown leaf rust', 'Leaf smut', 'Wheat black rust', 'thirps on  cotton', 'RedRot sugarcane', 'Gray_Leaf_Spot', 'Wheat powdery mildew']\n",
            "\n",
            "Train Class distribution:\n",
            "bacterial_blight in Cotton: 489 images\n",
            "RedRust sugarcane: 75 images\n",
            "Healthy Maize: 1162 images\n",
            "Wheat___Yellow_Rust: 92 images\n",
            "Tungro: 1308 images\n",
            "Wheat mite: 154 images\n",
            "Anthracnose on Cotton: 29 images\n",
            "Healthy Wheat: 180 images\n",
            "Cotton Aphid: 39 images\n",
            "Common_Rust: 1306 images\n",
            "American Bollworm on Cotton: 56 images\n",
            "Yellow Rust Sugarcane: 505 images\n",
            "Flag Smut: 179 images\n",
            "Wheat scab: 95 images\n",
            "Army worm: 40 images\n",
            "cotton whitefly: 54 images\n",
            "Wheat leaf blight: 143 images\n",
            "Healthy cotton: 425 images\n",
            "Wilt: 419 images\n",
            "bollrot on Cotton: 2 images\n",
            "Rice Blast: 1440 images\n",
            "Becterial Blight in Rice: 1584 images\n",
            "cotton mealy bug: 92 images\n",
            "maize ear rot: 115 images\n",
            "Wheat Stem fly: 172 images\n",
            "Mosaic sugarcane: 462 images\n",
            "Sugarcane Healthy: 522 images\n",
            "red cotton bug: 69 images\n",
            "maize stem borer: 95 images\n",
            "Brownspot: 1640 images\n",
            "bollworm on Cotton: 22 images\n",
            "pink bollworm in cotton: 28 images\n",
            "Leaf Curl: 417 images\n",
            "Wheat aphid: 156 images\n",
            "maize fall armyworm: 107 images\n",
            "Wheat Brown leaf Rust: 90 images\n",
            "Leaf smut: 40 images\n",
            "Wheat black rust: 161 images\n",
            "thirps on  cotton: 36 images\n",
            "RedRot sugarcane: 592 images\n",
            "Gray_Leaf_Spot: 574 images\n",
            "Wheat powdery mildew: 169 images\n",
            "\n",
            "Validation Class distribution:\n",
            "RedRust sugarcane: 31 images\n",
            "Healthy Maize: 275 images\n",
            "Wheat___Yellow_Rust: 19 images\n",
            "Tungro: 9 images\n",
            "Wheat mite: 38 images\n",
            "Anthracnose on Cotton: 10 images\n",
            "Healthy Wheat: 33 images\n",
            "Cotton Aphid: 287 images\n",
            "Common_Rust: 18 images\n",
            "American Bollworm on Cotton: 30 images\n",
            "Yellow Rust Sugarcane: 4 images\n",
            "Flag Smut: 24 images\n",
            "Wheat scab: 23 images\n",
            "Army worm: 351 images\n",
            "cotton whitefly: 44 images\n",
            "Bacterial Blight in cotton: 284 images\n",
            "Wheat leaf blight: 35 images\n",
            "Healthy cotton: 176 images\n",
            "Wilt: 419 images\n",
            "bollrot on Cotton: 2 images\n",
            "Rice Blast: 44 images\n",
            "Becterial Blight in Rice: 22 images\n",
            "cotton mealy bug: 58 images\n",
            "maize ear rot: 18 images\n",
            "Wheat Stem fly: 62 images\n",
            "Mosaic sugarcane: 66 images\n",
            "Sugarcane Healthy: 94 images\n",
            "red cotton bug: 44 images\n",
            "maize stem borer: 57 images\n",
            "Brownspot: 9 images\n",
            "bollworm on Cotton: 10 images\n",
            "pink bollworm in cotton: 28 images\n",
            "Leaf Curl: 81 images\n",
            "Wheat aphid: 38 images\n",
            "maize fall armyworm: 75 images\n",
            "Wheat Brown leaf rust: 15 images\n",
            "Leaf smut: 16 images\n",
            "Wheat black rust: 70 images\n",
            "thirps on  cotton: 36 images\n",
            "RedRot sugarcane: 153 images\n",
            "Gray_Leaf_Spot: 20 images\n",
            "Wheat powdery mildew: 42 images\n",
            "Class names: ['American Bollworm on Cotton', 'Anthracnose on Cotton', 'Army worm', 'Becterial Blight in Rice', 'Brownspot', 'Common_Rust', 'Cotton Aphid', 'Flag Smut', 'Gray_Leaf_Spot', 'Healthy Maize', 'Healthy Wheat', 'Healthy cotton', 'Leaf Curl', 'Leaf smut', 'Mosaic sugarcane', 'RedRot sugarcane', 'RedRust sugarcane', 'Rice Blast', 'Sugarcane Healthy', 'Tungro', 'Wheat Brown leaf Rust', 'Wheat Stem fly', 'Wheat aphid', 'Wheat black rust', 'Wheat leaf blight', 'Wheat mite', 'Wheat powdery mildew', 'Wheat scab', 'Wheat___Yellow_Rust', 'Wilt', 'Yellow Rust Sugarcane', 'bacterial_blight in Cotton', 'bollrot on Cotton', 'bollworm on Cotton', 'cotton mealy bug', 'cotton whitefly', 'maize ear rot', 'maize fall armyworm', 'maize stem borer', 'pink bollworm in cotton', 'red cotton bug', 'thirps on  cotton']\n",
            "Number of classes: 42\n",
            "Found 15450 potential image files in the training directory.\n",
            "\n",
            "Datasets created and optimized using manual loading with error handling and explicit shape setting.\n",
            "Epoch 1/15\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     12/Unknown \u001b[1m19s\u001b[0m 1s/step - accuracy: 0.0702 - loss: 3.6916Error decoding image /kaggle/input/20k-multi-class-crop-disease-images/Train/maize ear rot/00000073.jpg: {{function_node __wrapped__DecodeImage_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeImage] name: \n",
            "     43/Unknown \u001b[1m53s\u001b[0m 1s/step - accuracy: 0.0922 - loss: 3.5216Error decoding image /kaggle/input/20k-multi-class-crop-disease-images/Train/pink bollworm in cotton/Image_39.jpg: {{function_node __wrapped__DecodeImage_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeImage] name: \n",
            "     47/Unknown \u001b[1m58s\u001b[0m 1s/step - accuracy: 0.0932 - loss: 3.5073Error decoding image /kaggle/input/20k-multi-class-crop-disease-images/Train/Wheat powdery mildew/00001348.jpg: {{function_node __wrapped__DecodeImage_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeImage] name: \n",
            "     55/Unknown \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.0949 - loss: 3.4815Error decoding image /kaggle/input/20k-multi-class-crop-disease-images/Train/Wheat powdery mildew/00001358.jpg: {{function_node __wrapped__DecodeImage_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeImage] name: \n",
            "Error decoding image /kaggle/input/20k-multi-class-crop-disease-images/Train/cotton mealy bug/Image_88.png: {{function_node __wrapped__DecodeImage_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeImage] name: \n",
            "     67/Unknown \u001b[1m81s\u001b[0m 1s/step - accuracy: 0.0970 - loss: 3.4511Error decoding image /kaggle/input/20k-multi-class-crop-disease-images/Train/Wheat powdery mildew/00001345.jpg: {{function_node __wrapped__DecodeImage_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeImage] name: \n",
            "     69/Unknown \u001b[1m85s\u001b[0m 1s/step - accuracy: 0.0973 - loss: 3.4464Error decoding image /kaggle/input/20k-multi-class-crop-disease-images/Train/Wheat powdery mildew/00001323.jpg: {{function_node __wrapped__DecodeImage_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeImage] name: \n",
            "     72/Unknown \u001b[1m88s\u001b[0m 1s/step - accuracy: 0.0979 - loss: 3.4398Error decoding image /kaggle/input/20k-multi-class-crop-disease-images/Train/Wheat powdery mildew/00001359.jpg: {{function_node __wrapped__DecodeImage_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeImage] name: \n",
            "Error decoding image /kaggle/input/20k-multi-class-crop-disease-images/Train/Healthy Wheat/Wheat___Healthy: {{function_node __wrapped__ReadFile_device_/job:localhost/replica:0/task:0/device:CPU:0}} /kaggle/input/20k-multi-class-crop-disease-images/Train/Healthy Wheat/Wheat___Healthy; Is a directory [Op:ReadFile]\n",
            "     86/Unknown \u001b[1m103s\u001b[0m 1s/step - accuracy: 0.1001 - loss: 3.4123Error decoding image /kaggle/input/20k-multi-class-crop-disease-images/Train/Wheat powdery mildew/00001341.jpg: {{function_node __wrapped__DecodeImage_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeImage] name: \n",
            "     87/Unknown \u001b[1m104s\u001b[0m 1s/step - accuracy: 0.1003 - loss: 3.4105Error decoding image /kaggle/input/20k-multi-class-crop-disease-images/Train/Wheat powdery mildew/00001332.jpg: {{function_node __wrapped__DecodeImage_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeImage] name: \n",
            "     94/Unknown \u001b[1m111s\u001b[0m 1s/step - accuracy: 0.1012 - loss: 3.3986Error decoding image /kaggle/input/20k-multi-class-crop-disease-images/Train/Wheat powdery mildew/00001342.jpg: {{function_node __wrapped__DecodeImage_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeImage] name: \n",
            "    100/Unknown \u001b[1m118s\u001b[0m 1s/step - accuracy: 0.1018 - loss: 3.3892Error decoding image /kaggle/input/20k-multi-class-crop-disease-images/Train/Healthy cotton/h420.webp: {{function_node __wrapped__DecodeImage_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeImage] name: \n",
            "    114/Unknown \u001b[1m132s\u001b[0m 1s/step - accuracy: 0.1027 - loss: 3.3700Error decoding image /kaggle/input/20k-multi-class-crop-disease-images/Train/Wheat powdery mildew/00001339.jpg: {{function_node __wrapped__DecodeImage_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeImage] name: \n",
            "    121/Unknown \u001b[1m138s\u001b[0m 1s/step - accuracy: 0.1028 - loss: 3.3613Error decoding image /kaggle/input/20k-multi-class-crop-disease-images/Train/bollworm on Cotton/Image_6.jpg: {{function_node __wrapped__DecodeImage_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeImage] name: \n",
            "    124/Unknown \u001b[1m142s\u001b[0m 1s/step - accuracy: 0.1029 - loss: 3.3578Error decoding image /kaggle/input/20k-multi-class-crop-disease-images/Train/Wheat powdery mildew/00001346.jpg: {{function_node __wrapped__DecodeImage_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeImage] name: \n",
            "Error decoding image /kaggle/input/20k-multi-class-crop-disease-images/Train/Wheat powdery mildew/00001329.jpg: {{function_node __wrapped__DecodeImage_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeImage] name: \n",
            "    138/Unknown \u001b[1m155s\u001b[0m 1s/step - accuracy: 0.1030 - loss: 3.3426Error decoding image /kaggle/input/20k-multi-class-crop-disease-images/Train/cotton mealy bug/Image_61.jpg: {{function_node __wrapped__DecodeImage_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeImage] name: \n",
            "    167/Unknown \u001b[1m185s\u001b[0m 1s/step - accuracy: 0.1031 - loss: 3.3161Error decoding image /kaggle/input/20k-multi-class-crop-disease-images/Train/Wheat powdery mildew/00001343.jpg: {{function_node __wrapped__DecodeImage_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeImage] name: \n",
            "    195/Unknown \u001b[1m214s\u001b[0m 1s/step - accuracy: 0.1029 - loss: 3.2969Error decoding image /kaggle/input/20k-multi-class-crop-disease-images/Train/maize ear rot/00000071.jpg: {{function_node __wrapped__DecodeImage_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeImage] name: \n",
            "    203/Unknown \u001b[1m221s\u001b[0m 1s/step - accuracy: 0.1028 - loss: 3.2921Error decoding image /kaggle/input/20k-multi-class-crop-disease-images/Train/pink bollworm in cotton/Image_42.jpg: {{function_node __wrapped__DecodeImage_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeImage] name: \n",
            "    206/Unknown \u001b[1m225s\u001b[0m 1s/step - accuracy: 0.1028 - loss: 3.2904Error decoding image /kaggle/input/20k-multi-class-crop-disease-images/Train/Wheat powdery mildew/00001335.jpg: {{function_node __wrapped__DecodeImage_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeImage] name: \n",
            "    211/Unknown \u001b[1m229s\u001b[0m 1s/step - accuracy: 0.1027 - loss: 3.2876Error decoding image /kaggle/input/20k-multi-class-crop-disease-images/Train/Wheat powdery mildew/00001347.jpg: {{function_node __wrapped__DecodeImage_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeImage] name: \n",
            "    258/Unknown \u001b[1m279s\u001b[0m 1s/step - accuracy: 0.1024 - loss: 3.2656Error decoding image /kaggle/input/20k-multi-class-crop-disease-images/Train/Wheat powdery mildew/00001351.jpg: {{function_node __wrapped__DecodeImage_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeImage] name: \n",
            "    275/Unknown \u001b[1m294s\u001b[0m 1s/step - accuracy: 0.1025 - loss: 3.2588Error decoding image /kaggle/input/20k-multi-class-crop-disease-images/Train/Wheat powdery mildew/00001350.jpg: {{function_node __wrapped__DecodeImage_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeImage] name: \n",
            "    277/Unknown \u001b[1m296s\u001b[0m 1s/step - accuracy: 0.1025 - loss: 3.2581Error decoding image /kaggle/input/20k-multi-class-crop-disease-images/Train/Wheat powdery mildew/00001352.jpg: {{function_node __wrapped__DecodeImage_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeImage] name: \n",
            "    279/Unknown \u001b[1m298s\u001b[0m 1s/step - accuracy: 0.1025 - loss: 3.2573Error decoding image /kaggle/input/20k-multi-class-crop-disease-images/Train/Wheat powdery mildew/00001327.jpg: {{function_node __wrapped__DecodeImage_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeImage] name: \n",
            "    302/Unknown \u001b[1m322s\u001b[0m 1s/step - accuracy: 0.1024 - loss: 3.2491Error decoding image /kaggle/input/20k-multi-class-crop-disease-images/Train/maize ear rot/00000114.jpeg: {{function_node __wrapped__DecodeImage_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeImage] name: \n",
            "    335/Unknown \u001b[1m355s\u001b[0m 1s/step - accuracy: 0.1023 - loss: 3.2394Error decoding image /kaggle/input/20k-multi-class-crop-disease-images/Train/Wheat powdery mildew/00001325.jpg: {{function_node __wrapped__DecodeImage_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeImage] name: \n",
            "    373/Unknown \u001b[1m397s\u001b[0m 1s/step - accuracy: 0.1021 - loss: 3.2302Error decoding image /kaggle/input/20k-multi-class-crop-disease-images/Train/Wheat powdery mildew/00001331.jpg: {{function_node __wrapped__DecodeImage_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeImage] name: \n",
            "    377/Unknown \u001b[1m402s\u001b[0m 1s/step - accuracy: 0.1021 - loss: 3.2293Error decoding image /kaggle/input/20k-multi-class-crop-disease-images/Train/Wheat powdery mildew/00001353.jpg: {{function_node __wrapped__DecodeImage_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeImage] name: \n",
            "    386/Unknown \u001b[1m408s\u001b[0m 1s/step - accuracy: 0.1021 - loss: 3.2274"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 1s/step - accuracy: 0.1021 - loss: 3.2272\n",
            "Epoch 2/15\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 717ms/step - accuracy: 0.0996 - loss: 3.1169\n",
            "Epoch 3/15\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 684ms/step - accuracy: 0.1000 - loss: 3.1154\n",
            "Epoch 4/15\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m344s\u001b[0m 742ms/step - accuracy: 0.1001 - loss: 3.1146\n",
            "Epoch 5/15\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 673ms/step - accuracy: 0.1035 - loss: 3.1138\n",
            "Epoch 6/15\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667ms/step - accuracy: 0.1053 - loss: 3.1133"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 679ms/step - accuracy: 0.1053 - loss: 3.1133\n",
            "Epoch 7/15\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 676ms/step - accuracy: 0.1058 - loss: 3.1128"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 679ms/step - accuracy: 0.1058 - loss: 3.1128\n",
            "Epoch 8/15\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 674ms/step - accuracy: 0.1037 - loss: 3.1124\n",
            "Epoch 9/15\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672ms/step - accuracy: 0.1012 - loss: 3.1121"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 679ms/step - accuracy: 0.1012 - loss: 3.1121\n",
            "Epoch 10/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 678ms/step - accuracy: 0.1059 - loss: 3.1114\n",
            "Epoch 11/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662ms/step - accuracy: 0.1062 - loss: 3.1109"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 678ms/step - accuracy: 0.1062 - loss: 3.1109\n",
            "Epoch 12/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665ms/step - accuracy: 0.1071 - loss: 3.1103"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 678ms/step - accuracy: 0.1071 - loss: 3.1103\n",
            "Epoch 13/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 677ms/step - accuracy: 0.1069 - loss: 3.1098\n",
            "Epoch 14/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 659ms/step - accuracy: 0.1065 - loss: 3.1092\n",
            "Epoch 15/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657ms/step - accuracy: 0.1070 - loss: 3.1089"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 679ms/step - accuracy: 0.1070 - loss: 3.1089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_19\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_19\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ sequential_18 (\u001b[38;5;33mSequential\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ rescaling_6 (\u001b[38;5;33mRescaling\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_33 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │           \u001b[38;5;34m448\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_33 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_34 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m4,640\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_34 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_35 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_35 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_11 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16384\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m2,097,280\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m42\u001b[0m)             │         \u001b[38;5;34m5,418\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ sequential_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ rescaling_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16384</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,280</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,418</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,378,848\u001b[0m (24.33 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,378,848</span> (24.33 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,126,282\u001b[0m (8.11 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,126,282</span> (8.11 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m4,252,566\u001b[0m (16.22 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,252,566</span> (16.22 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06beeaff"
      },
      "source": [
        "## LinkedIn Project Description\n",
        "\n",
        "Developed a Convolutional Neural Network (CNN) for multi-class crop disease image classification using TensorFlow and Keras. The project involved downloading and processing a large dataset of over 20,000 images, implementing data augmentation, and training a CNN model to identify 42 different crop diseases. This work highlights skills in image data handling, deep learning model development, and applying AI to agricultural challenges for improved crop health and yield."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}